{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regression Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    root_mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preparing the Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "y_true = np.array([10, -1.5, 8, 7, 9.5, 11])  # Actual values\n",
    "y_pred = np.array([9.9, -1, 8, 6, 10, 10.5])  # Predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Mean Absolute Error (MAE)**\n",
    "- **Definition**: MAE measures the average absolute difference between the predicted and actual values.\n",
    "  \n",
    "- **Formula**:\n",
    "  $$\n",
    "  \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "  $$\n",
    "- **Interpretation**:\n",
    "  - Lower values indicate better performance.\n",
    "  - MAE is easy to interpret because it is in the same units as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.4333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Mean Squared Error (MSE)**\n",
    "- **Definition**: MSE measures the average squared difference between the predicted and actual values.\n",
    "  \n",
    "- **Formula**:\n",
    "  $$\n",
    "  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "  $$\n",
    "- **Interpretation**:\n",
    "  - Lower values indicate better performance.\n",
    "  - MSE penalizes larger errors more heavily because of the squaring.\n",
    "- **Output**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.29333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(f\"MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Root Mean Squared Error (RMSE)**\n",
    "- **Definition**: RMSE is the square root of MSE. It provides the error in the same units as the target variable.\n",
    "  \n",
    "- **Formula**:\n",
    "  $$\n",
    "  \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "  $$\n",
    "- **Interpretation**:\n",
    "  - Lower values indicate better performance.\n",
    "  - RMSE is more interpretable than MSE because it is in the same units as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5416025603090641\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "# rmse = np.sqrt(mse)  # RMSE is the square root of MSE\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **R-squared (R²) Score**  \n",
    "- **Definition**: R² (coefficient of determination) measures how well the predicted values explain the variation in the actual values. It shows the proportion of variance in the dependent variable that is predictable from the independent variables.  \n",
    "\n",
    "- **Formula**:\n",
    "  $$\n",
    "  R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "  $$\n",
    "  where $\\bar{y}$ is the mean of the actual values.\n",
    "\n",
    "- **Interpretation**:  \n",
    "  - $R^2$ ranges from **negative values to 1**.  \n",
    "  - **$R^2 = 1$** → Perfect fit (the model explains 100% of the variance).  \n",
    "  - **$R^2 = 0$** → The model explains **none** of the variance.  \n",
    "  - **$R^2 < 0$** → The model is worse than simply using the mean of the actual values as a prediction.  \n",
    "  - **Higher $R^2$ values** indicate better model performance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9830497592295345\n"
     ]
    }
   ],
   "source": [
    "# Calculate R² Score (R-squared)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Summary of Metrics**\n",
    "| Metric       | Description                                                                 | Interpretation                          |\n",
    "|--------------|-----------------------------------------------------------------------------|-----------------------------------------|\n",
    "| **MAE**      | Average absolute difference between predicted and actual values.            | Lower is better.                        |\n",
    "| **MSE**      | Average squared difference between predicted and actual values.             | Lower is better.                        |\n",
    "| **RMSE**     | Square root of MSE, error in the same units as the target variable.          | Lower is better.                        |\n",
    "| **R² Score** | Proportion of variance in the target variable explained by the model.        | Closer to 1 is better.                  |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Each Metric\n",
    "- **MAE**: Use when you want a simple, interpretable metric for average error.\n",
    "- **MSE/RMSE**: Use when you want to penalize larger errors more heavily.\n",
    "- **R² Score**: Use to evaluate how well the model explains the variance in the data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regression Metrics Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Metrics Summary:\n",
      "——————————————————————————————————\n",
      "Mean Absolute Error (MAE):  0.4333\n",
      "Mean Squared Error (MSE):   0.2933\n",
      "Root Mean Squared Error:    0.5416\n",
      "R-squared Score (R²):       0.9830\n",
      "——————————————————————————————————\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    root_mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RegressionMetrics:\n",
    "    def __init__(self, y_true, y_pred):\n",
    "        self.y_true = np.array(y_true)\n",
    "        self.y_pred = np.array(y_pred)\n",
    "\n",
    "    def calculate_metrics(self):\n",
    "        self.mae = mean_absolute_error(self.y_true, self.y_pred)\n",
    "        self.mse = mean_squared_error(self.y_true, self.y_pred)\n",
    "        self.rmse = root_mean_squared_error(self.y_true, self.y_pred)\n",
    "        self.r2 = r2_score(self.y_true, self.y_pred)\n",
    "\n",
    "        return self.mae, self.mse, self.rmse, self.r2\n",
    "\n",
    "    def display_metrics(self):\n",
    "        print(\"Regression Metrics Summary:\")\n",
    "        print(\"—\" * 34)\n",
    "        print(f\"Mean Absolute Error (MAE):  {self.mae:.4f}\")\n",
    "        print(f\"Mean Squared Error (MSE):   {self.mse:.4f}\")\n",
    "        print(f\"Root Mean Squared Error:    {self.rmse:.4f}\")\n",
    "        print(f\"R-squared Score (R²):       {self.r2:.4f}\")\n",
    "        print(\"—\" * 34)\n",
    "\n",
    "    def run(self):\n",
    "        self.calculate_metrics()\n",
    "        self.display_metrics()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "y_true = [10, -1.5, 8, 7, 9.5, 11]\n",
    "y_pred = [9.9, -1, 8, 6, 10, 10.5]\n",
    "\n",
    "metrics = RegressionMetrics(y_true, y_pred)\n",
    "metrics.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
